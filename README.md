# Ex.No: 2 	Evaluation of 2024 Prompting Tools Across Diverse AI Platforms: 
ChatGPT, Claude, Bard, Cohere Command, and Meta 
### DATE: 26/04/2025                                                                           
### REGISTER NUMBER : 2122223040030
### Aim:
To compare the performance, user experience, and response quality of different AI platforms (ChatGPT, Claude, Bard, Cohere Command, and Meta) within a specific use case, such as summarizing text or answering technical questions. Generate a Prompt based output using different Prompting tools of 2024.

###  Introduction
Introduction
Artificial Intelligence (AI) technologies have seen rapid development and integration into various industries. As AI-powered platforms become more widespread, evaluating their performance and suitability for different tasks is critical. One important task for AI tools is summarizing complex content into digestible, accurate, and student-friendly formats. The ability of AI models to summarize technical texts in simple terms for educational purposes is vital for their application in learning environments.

This experiment evaluates five popular AI platforms—ChatGPT, Claude, Bard, Cohere Command, and Meta—across a standardized task to compare their ability to summarize technical content. The goal is to assess each platform’s response accuracy, clarity, depth, and relevance to determine their effectiveness in educational applications.
###  Methodology
#### Use Case Definition
Task: Summarizing a technical paragraph on Artificial Intelligence for college students.

Rationale: Summarizing technical content in an accessible way ensures that platforms can handle complex concepts and deliver them effectively. This use case was selected to evaluate clarity and adaptability in educational contexts.

#### Uniform Prompt
The same prompt was provided to all platforms:

Prompt: “Summarize the following paragraph on Artificial Intelligence in simple terms for college students.”

##### Input Paragraph:

"Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are designed to think and act like humans. These systems can learn from data, identify patterns, and make decisions with minimal human intervention. AI technologies include machine learning, natural language processing, robotics, and more. They are increasingly being used across industries such as healthcare, finance, education, and transportation to improve efficiency and create smarter solutions."

#### Execution of Experiment
The same prompt was input into the following platforms:

ChatGPT (GPT-4)
Claude (Claude 3)
Bard (Gemini 1.5)
Cohere Command R+
Meta (LLaMA 2)
Responses were collected, and response times, usability, and general observations were noted. These responses were then scored based on four metrics:
#### Accuracy: Factual correctness of the summary.
#### Clarity: How readable and understandable the summary is.
#### Depth: Coverage of key concepts, technical details, and the breadth of explanation.
#### Relevance: How well the summary adheres to the prompt and remains focused on summarizing the technical content.
### Results and Comparative Analysis
#### Collected Responses
#### ChatGPT (GPT-4):

"AI mimics human thinking in machines, enabling them to learn from data, spot patterns, and make decisions. It includes tech like machine learning and robotics, and is used in healthcare, finance, and more to boost efficiency."
Strengths: Balanced, concise, and student-friendly.
#### Claude (Claude 3):
"AI is about creating machines that think like humans. They learn from data, recognize patterns, and act autonomously. Key areas are machine learning and robotics, with applications in healthcare, education, etc."
Strengths: Well-structured and accurate.
#### Bard (Gemini 1.5):
"AI lets machines perform human-like tasks by learning from data. It powers tools like chatbots and self-driving cars across industries."
Strengths: Simple but slightly superficial.
#### Cohere Command R+:
"AI is machines acting smartly. They learn and decide things, used in many fields."
Weaknesses: Overly simplified; misses technical nuances.
#### Meta (LLaMA 2):
"AI makes machines smart like people. It helps in jobs and learning."
Weaknesses: Vague and less polished
#### Comparison Table
![image](https://github.com/user-attachments/assets/3b03d606-cfdf-41d4-8b10-270d5bd55ea5)
### Analysis & Discussion
#### ChatGPT (GPT-4): 
This platform excelled in all areas, particularly clarity and relevance. The summary was both concise and accurate, with just the right amount of detail for college students. Its strengths make it ideal for educational use, where students need clear and precise information without over-simplification.

#### Claude (Claude 3):
Claude performed well, though slightly less accurate than ChatGPT in its explanations. It did, however, maintain strong clarity and relevance, which could make it suitable for educational contexts, albeit with slightly less depth than ChatGPT.

#### Bard (Gemini 1.5): 
Bard’s summary was quick and simple, but it lacked depth and technical coverage. This makes it more suitable for quick summaries but not for detailed educational use where understanding the underlying concepts is key.

#### Cohere Command R+:
Cohere’s summary was overly simplified, lacking the technical depth needed for a comprehensive understanding. This tool might be best for general audiences or for contexts where extreme simplicity is required, but not for technical education.

#### Meta (LLaMA 2): 
Meta’s output was vague and lacked both depth and clarity. It scored poorly across all metrics and should likely be avoided for technical summarization tasks in educational settings.

![Screenshot 2025-04-25 085521](https://github.com/user-attachments/assets/f1ce6cd4-7078-4bd4-ab0f-403f18287049)


### Conclusion
This experiment has successfully compared the performance of five leading AI platforms in summarizing technical content. While ChatGPT (GPT-4) is the top performer due to its clarity, accuracy, and relevance, other tools like Claude also perform well, though with slightly less technical depth. Bard provides quick summaries but sacrifices depth for simplicity. Cohere and Meta should be used cautiously for educational purposes, as they fall short in clarity and technical depth.
### Result:
Thus the Prompting tools are executed and analysed sucessfully .
